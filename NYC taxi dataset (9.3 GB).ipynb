{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arprakash\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 642.2118389606476 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# first let us try to import the data with pandas\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df=pd.read_csv(r'C:\\nyc-taxi-dataset\\combined\\2019-NYC-taxi-data.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-01-01 00:59:47</td>\n",
       "      <td>2019-01-01 01:18:59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-12-21 13:48:30</td>\n",
       "      <td>2018-12-21 13:52:40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-11-28 15:52:25</td>\n",
       "      <td>2018-11-28 15:55:45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-11-28 15:56:57</td>\n",
       "      <td>2018-11-28 15:58:33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>55.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0           0       1.0  2019-01-01 00:46:40   2019-01-01 00:53:20   \n",
       "1           1       1.0  2019-01-01 00:59:47   2019-01-01 01:18:59   \n",
       "2           2       2.0  2018-12-21 13:48:30   2018-12-21 13:52:40   \n",
       "3           3       2.0  2018-11-28 15:52:25   2018-11-28 15:55:45   \n",
       "4           4       2.0  2018-11-28 15:56:57   2018-11-28 15:58:33   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0              1.0            1.5         1.0                  N   \n",
       "1              1.0            2.6         1.0                  N   \n",
       "2              3.0            0.0         1.0                  N   \n",
       "3              5.0            0.0         1.0                  N   \n",
       "4              5.0            0.0         2.0                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           151           239           1.0          7.0    0.5      0.5   \n",
       "1           239           246           1.0         14.0    0.5      0.5   \n",
       "2           236           236           1.0          4.5    0.5      0.5   \n",
       "3           193           193           2.0          3.5    0.5      0.5   \n",
       "4           193           193           2.0         52.0    0.0      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        1.65           0.0                    0.3          9.95   \n",
       "1        1.00           0.0                    0.3         16.30   \n",
       "2        0.00           0.0                    0.3          5.80   \n",
       "3        0.00           0.0                    0.3          7.55   \n",
       "4        0.00           0.0                    0.3         55.55   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that's around six minutes, but pandas did read it wow!\n",
    "\n",
    "# eleven minutes the second time, first time i restarted so all memory cache was cleared and hence faster? maybe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84399019 entries, 0 to 84399018\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Unnamed: 0             int64  \n",
      " 1   VendorID               float64\n",
      " 2   tpep_pickup_datetime   object \n",
      " 3   tpep_dropoff_datetime  object \n",
      " 4   passenger_count        float64\n",
      " 5   trip_distance          float64\n",
      " 6   RatecodeID             float64\n",
      " 7   store_and_fwd_flag     object \n",
      " 8   PULocationID           int64  \n",
      " 9   DOLocationID           int64  \n",
      " 10  payment_type           float64\n",
      " 11  fare_amount            float64\n",
      " 12  extra                  float64\n",
      " 13  mta_tax                float64\n",
      " 14  tip_amount             float64\n",
      " 15  tolls_amount           float64\n",
      " 16  improvement_surcharge  float64\n",
      " 17  total_amount           float64\n",
      " 18  congestion_surcharge   float64\n",
      "dtypes: float64(13), int64(3), object(3)\n",
      "memory usage: 11.9+ GB\n"
     ]
    }
   ],
   "source": [
    "# let us see the info of the data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://AJG-L020966.emea.ajgco.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>first_spark_application</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x22d83a2cf08>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let us try with pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".master('local[*]') \\\n",
    ".appName('first_spark_application') \\\n",
    ".getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us define the schema below and import it to spark.read.csv later\n",
    "\n",
    "#from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\n",
    "\n",
    "#schema = StructType([StructField(\"vendor_id\", IntegerType()),StructField(\" pickup_datetime\", TimestampType()),\n",
    "  #                   StructField(\" dropoff_datetime\",TimestampType()),StructField(\" passenger_count\", IntegerType()),\n",
    "    #                 StructField(\" trip_distance\",DoubleType()),StructField(\" pickup_longitude\",DoubleType()),\n",
    "  #                   StructField(\" pickup_latitude\",DoubleType()),StructField(\" rate_code\",IntegerType()),\n",
    "  #                   StructField(\" store_and_fwd_flag\",StringType()),StructField(\" dropoff_longitude\",DoubleType()),\n",
    "  #                   StructField(\" dropoff_latitude\",DoubleType()),StructField(\" payment_type\",StringType()),\n",
    "  #                   StructField(\" fare_amount\",DoubleType()),StructField(\" surcharge\",DoubleType()),\n",
    "  #                   StructField(\" mta_tax\",DoubleType()),StructField(\" tip_amount\",DoubleType()),\n",
    "  #                   StructField(\" tolls_amount\",DoubleType()),StructField(\" total_amount\",DoubleType())                 \n",
    "                     \n",
    "     #                 ])\n",
    "\n",
    "#schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|_c0|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+---+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|  0|     1.0| 2019-01-01 00:46:40|  2019-01-01 00:53:20|            1.0|          1.5|       1.0|                 N|         151|         239|         1.0|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null|\n",
      "|  1|     1.0| 2019-01-01 00:59:47|  2019-01-01 01:18:59|            1.0|          2.6|       1.0|                 N|         239|         246|         1.0|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                null|\n",
      "|  2|     2.0| 2018-12-21 13:48:30|  2018-12-21 13:52:40|            3.0|          0.0|       1.0|                 N|         236|         236|         1.0|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                null|\n",
      "|  3|     2.0| 2018-11-28 15:52:25|  2018-11-28 15:55:45|            5.0|          0.0|       1.0|                 N|         193|         193|         2.0|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        7.55|                null|\n",
      "|  4|     2.0| 2018-11-28 15:56:57|  2018-11-28 15:58:33|            5.0|          0.0|       2.0|                 N|         193|         193|         2.0|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                null|\n",
      "+---+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "--- 8.863844633102417 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# let us read the data with spark\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_spark = spark.read.csv(r'C:\\nyc-taxi-dataset\\combined\\2019-NYC-taxi-data.csv',header=True, nullValue='NA')\n",
    "\n",
    "df_spark.show(5)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without inferring schema, spark can read this in 9 seconds wow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not bad, 45 seconds to evaluate some 84 million rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# without inferSchema, everything should be string type\n",
    "\n",
    "# let us verify that\n",
    "\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tpep_pickup_datetime', 'timestamp')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us see if casting works to change data types\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "df_spark = df_spark.withColumn('tpep_pickup_datetime',to_timestamp(df_spark['tpep_pickup_datetime']))\n",
    "\n",
    "df_spark.select('tpep_pickup_datetime').dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wow, this method seems to be working\n",
    "\n",
    "how about we put all the metadata information like this for any columns other than string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: double (nullable = true)\n",
      " |-- DOLocationID: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\n",
    "\n",
    "df_spark = df_spark.withColumn('tpep_dropoff_datetime',to_timestamp(df_spark['tpep_dropoff_datetime']))\n",
    "\n",
    "df_spark = df_spark.withColumn('passenger_count',df_spark['passenger_count'].cast(IntegerType()))\n",
    "\n",
    "df_spark = df_spark.withColumn('trip_distance',df_spark['trip_distance'].cast(DoubleType()))  \n",
    "\n",
    "df_spark = df_spark.withColumn('PULocationID',df_spark['PULocationID'].cast(DoubleType())) \n",
    "\n",
    "df_spark = df_spark.withColumn('DOLocationID',df_spark['DOLocationID'].cast(DoubleType())) \n",
    "\n",
    "df_spark = df_spark.withColumn('fare_amount',df_spark['fare_amount'].cast(DoubleType())) \n",
    "\n",
    "df_spark = df_spark.withColumn('extra',df_spark['extra'].cast(DoubleType())) \n",
    "\n",
    "df_spark = df_spark.withColumn('mta_tax',df_spark['mta_tax'].cast(DoubleType())) \n",
    "\n",
    "df_spark = df_spark.withColumn('tip_amount',df_spark['tip_amount'].cast(DoubleType())) \n",
    "\n",
    "df_spark = df_spark.withColumn('tolls_amount',df_spark['tolls_amount'].cast(DoubleType())) \n",
    "\n",
    "df_spark = df_spark.withColumn('improvement_surcharge',df_spark['improvement_surcharge'].cast(DoubleType())) \n",
    "\n",
    "df_spark = df_spark.withColumn('total_amount',df_spark['total_amount'].cast(DoubleType())) \n",
    "\n",
    "df_spark = df_spark.withColumn('congestion_surcharge',df_spark['congestion_surcharge'].cast(DoubleType())) \n",
    "\n",
    "# let us print the schema and verify that everything is complete\n",
    "\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it has been executued! Wow, we now know to get back the schema in pyspark instead of wasting team inferring the schema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84399019\n",
      "--- 68.16249537467957 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# how many rows are we exploring\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(df_spark.count())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wow, 84 million rows and spark took 68 seconds to answer that question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1614077495.766805\n",
      "--- 175.7431800365448 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# what is the total amount of all taxi fares for year of 2019\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(df_spark.agg({'total_amount':'sum'}).collect()[0][0])\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that is an incredible $ 1.61 billion spent in taxi fares for a year.\n",
    "\n",
    "No wonder uber is a unicorn!\n",
    "\n",
    "Spark has done that calculation for us in three minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1614077495.7499979\n",
      "--- 5.7549028396606445 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# how long will pandas take\n",
    "\n",
    "# let us find out\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print (df['total_amount'].sum())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wow, pandas was lightning fast\n",
    "\n",
    "and probably because it has already got all the data in memory when we loaded it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+---------------------+\n",
      "|total_amount|mta_tax|total amount less tax|\n",
      "+------------+-------+---------------------+\n",
      "|        9.95|    0.5|                 9.45|\n",
      "|        16.3|    0.5|                 15.8|\n",
      "|         5.8|    0.5|                  5.3|\n",
      "|        7.55|    0.5|                 7.05|\n",
      "|       55.55|    0.5|                55.05|\n",
      "+------------+-------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "--- 0.6706459522247314 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# how fast will pandas and spark perform on computation\n",
    "\n",
    "# for e.g., let us add in a column with spark first\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_spark = df_spark.withColumn('total amount less tax',df_spark['total_amount']-df_spark['mta_tax'])\n",
    "\n",
    "print(df_spark.select('total_amount','mta_tax','total amount less tax').show(5))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wow, spark does it in less than a second amazing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "0           0       1.0  2019-01-01 00:46:40   2019-01-01 00:53:20   \n",
      "1           1       1.0  2019-01-01 00:59:47   2019-01-01 01:18:59   \n",
      "2           2       2.0  2018-12-21 13:48:30   2018-12-21 13:52:40   \n",
      "3           3       2.0  2018-11-28 15:52:25   2018-11-28 15:55:45   \n",
      "4           4       2.0  2018-11-28 15:56:57   2018-11-28 15:58:33   \n",
      "\n",
      "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "0              1.0            1.5         1.0                  N   \n",
      "1              1.0            2.6         1.0                  N   \n",
      "2              3.0            0.0         1.0                  N   \n",
      "3              5.0            0.0         1.0                  N   \n",
      "4              5.0            0.0         2.0                  N   \n",
      "\n",
      "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
      "0           151           239           1.0          7.0    0.5      0.5   \n",
      "1           239           246           1.0         14.0    0.5      0.5   \n",
      "2           236           236           1.0          4.5    0.5      0.5   \n",
      "3           193           193           2.0          3.5    0.5      0.5   \n",
      "4           193           193           2.0         52.0    0.0      0.5   \n",
      "\n",
      "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
      "0        1.65           0.0                    0.3          9.45   \n",
      "1        1.00           0.0                    0.3         15.80   \n",
      "2        0.00           0.0                    0.3          5.30   \n",
      "3        0.00           0.0                    0.3          7.05   \n",
      "4        0.00           0.0                    0.3         55.05   \n",
      "\n",
      "   congestion_surcharge  total_amount less tax  \n",
      "0                   NaN                   8.95  \n",
      "1                   NaN                  15.30  \n",
      "2                   NaN                   4.80  \n",
      "3                   NaN                   6.55  \n",
      "4                   NaN                  54.55  \n",
      "--- 0.8415288925170898 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# now how about pandas\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df['total_amount less tax']=df['total_amount']-df['mta_tax']\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "again, a very decent less than a second operation with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|tpep_pickup_datetime|Month number|\n",
      "+--------------------+------------+\n",
      "| 2019-01-01 00:46:40|           1|\n",
      "| 2019-01-01 00:59:47|           1|\n",
      "| 2018-12-21 13:48:30|          12|\n",
      "| 2018-11-28 15:52:25|          11|\n",
      "| 2018-11-28 15:56:57|          11|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "--- 0.4616222381591797 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# let us see money spend on taxi's by month\n",
    "\n",
    "# let us first extract the month from the date column\n",
    "\n",
    "from pyspark.sql.functions import month\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_spark=df_spark.withColumn('Month number',month(df_spark['tpep_pickup_datetime']))\n",
    "\n",
    "print(df_spark.select('tpep_pickup_datetime','Month number').show(5))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "again, very fast in pyspark wow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|Month number|   sum(total_amount)|\n",
      "+------------+--------------------+\n",
      "|          12| 1.354624075912886E8|\n",
      "|           1|1.2025571111114666E8|\n",
      "|           6| 1.370208758012431E8|\n",
      "|           3|1.5031053158140665E8|\n",
      "|           5|1.4776838935147017E8|\n",
      "|           9|1.3081726913124491E8|\n",
      "|           4|1.4293865640143976E8|\n",
      "|           8|1.1951251739124504E8|\n",
      "|           7|1.2376032823118111E8|\n",
      "|          10|1.4249212155130276E8|\n",
      "|          11|1.3348042147113205E8|\n",
      "|           2|1.3025826615111229E8|\n",
      "+------------+--------------------+\n",
      "\n",
      "None\n",
      "--- 309.1172311306 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# let us group the taxi money by month\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_spark_bymonth = df_spark.groupBy('Month number').sum('total_amount')\n",
    "\n",
    "print(df_spark_bymonth.show())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wow, that was intense! took 5 minutes to finish those calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how will pandas fare?\n",
    "\n",
    "# first convert the pickup datetime to datetime formats\n",
    "\n",
    "df['tpep_pickup_datetime']=pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "# did that work\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
